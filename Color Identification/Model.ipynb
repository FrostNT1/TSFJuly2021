{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d0f5f0b",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f30afbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd6d111",
   "metadata": {},
   "source": [
    "### Getting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7b6db7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = './ColorClassification'\n",
    "CATEGORIES = ['orange','Violet','red','Blue','Green','Black','Brown','White']\n",
    "IMG_SIZE=100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a40c89a",
   "metadata": {},
   "source": [
    "### Performing Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6d99ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data=[]\n",
    "def create_training_data():\n",
    "    for category in CATEGORIES:\n",
    "        path=os.path.join(DATADIR, category)\n",
    "        class_num=CATEGORIES.index(category)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_array=cv2.imread(os.path.join(path,img))\n",
    "                new_array=cv2.resize(img_array,(IMG_SIZE,IMG_SIZE))\n",
    "                training_data.append([new_array,class_num])\n",
    "            except Exception as e:\n",
    "                pass\n",
    "create_training_data()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7990f3fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107\n"
     ]
    }
   ],
   "source": [
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fedf40a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "589ef5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[]\n",
    "y=[]\n",
    "\n",
    "for categories, label in training_data:\n",
    "    X.append(categories)\n",
    "    y.append(label)\n",
    "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a0ba066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(107, 100, 100, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54f4f650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(107,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8011e32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b41dff2",
   "metadata": {},
   "source": [
    "#### Flatten the array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29f49796",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98ae0d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.get_dummies(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47ad897",
   "metadata": {},
   "source": [
    "## Creating model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de38534f",
   "metadata": {},
   "source": [
    "We can use many differnt models, CNN would probably be the best model to use in this scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a09fff29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8198330",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu', input_shape=X.shape[1:]))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(8, activation='softmax'))\n",
    "\n",
    "#Compilation of the model\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy', \n",
    "    optimizer='adam', \n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2144d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "3/3 [==============================] - 17s 782ms/step - loss: 2.3560 - accuracy: 0.0625 - val_loss: 2.2034 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/30\n",
      "3/3 [==============================] - 1s 439ms/step - loss: 1.9608 - accuracy: 0.1315 - val_loss: 2.0831 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "3/3 [==============================] - 1s 440ms/step - loss: 1.7007 - accuracy: 0.3685 - val_loss: 2.2865 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "3/3 [==============================] - 1s 446ms/step - loss: 1.4152 - accuracy: 0.4466 - val_loss: 2.1949 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "3/3 [==============================] - 1s 447ms/step - loss: 1.3089 - accuracy: 0.4440 - val_loss: 1.8862 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "3/3 [==============================] - 1s 442ms/step - loss: 1.1355 - accuracy: 0.6615 - val_loss: 1.8925 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/30\n",
      "3/3 [==============================] - 1s 448ms/step - loss: 0.9487 - accuracy: 0.6393 - val_loss: 1.9389 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/30\n",
      "3/3 [==============================] - 1s 441ms/step - loss: 0.8137 - accuracy: 0.6953 - val_loss: 1.7906 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/30\n",
      "3/3 [==============================] - 1s 444ms/step - loss: 0.6221 - accuracy: 0.8672 - val_loss: 1.7905 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/30\n",
      "3/3 [==============================] - 1s 442ms/step - loss: 0.5012 - accuracy: 0.8763 - val_loss: 1.4526 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/30\n",
      "3/3 [==============================] - 1s 441ms/step - loss: 0.4533 - accuracy: 0.7930 - val_loss: 1.2280 - val_accuracy: 0.6364\n",
      "Epoch 12/30\n",
      "3/3 [==============================] - 1s 448ms/step - loss: 0.3286 - accuracy: 0.9714 - val_loss: 0.9783 - val_accuracy: 0.9091\n",
      "Epoch 13/30\n",
      "3/3 [==============================] - 1s 441ms/step - loss: 0.3128 - accuracy: 0.9193 - val_loss: 0.8496 - val_accuracy: 0.8182\n",
      "Epoch 14/30\n",
      "3/3 [==============================] - 1s 449ms/step - loss: 0.2335 - accuracy: 0.9453 - val_loss: 0.4441 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "3/3 [==============================] - 1s 448ms/step - loss: 0.3475 - accuracy: 0.9570 - val_loss: 7.0951 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/30\n",
      "3/3 [==============================] - 1s 441ms/step - loss: 1.4464 - accuracy: 0.7995 - val_loss: 0.1772 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "3/3 [==============================] - 1s 449ms/step - loss: 2.6173 - accuracy: 0.6523 - val_loss: 0.1019 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "3/3 [==============================] - 1s 452ms/step - loss: 0.9334 - accuracy: 0.6927 - val_loss: 0.4491 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "3/3 [==============================] - 1s 450ms/step - loss: 0.9255 - accuracy: 0.6979 - val_loss: 0.7400 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "3/3 [==============================] - 1s 454ms/step - loss: 0.7656 - accuracy: 0.7734 - val_loss: 1.1099 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "3/3 [==============================] - 1s 446ms/step - loss: 0.5525 - accuracy: 0.8333 - val_loss: 1.1909 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "3/3 [==============================] - 1s 455ms/step - loss: 0.5665 - accuracy: 0.8216 - val_loss: 1.0586 - val_accuracy: 0.4545\n",
      "Epoch 23/30\n",
      "3/3 [==============================] - 1s 443ms/step - loss: 0.3773 - accuracy: 0.9232 - val_loss: 0.8867 - val_accuracy: 0.3636\n",
      "Epoch 24/30\n",
      "3/3 [==============================] - 1s 448ms/step - loss: 0.3712 - accuracy: 0.8789 - val_loss: 0.6227 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "3/3 [==============================] - 1s 449ms/step - loss: 0.2205 - accuracy: 0.9753 - val_loss: 0.6836 - val_accuracy: 0.9091\n",
      "Epoch 26/30\n",
      "3/3 [==============================] - 1s 488ms/step - loss: 0.2355 - accuracy: 0.9609 - val_loss: 0.4550 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "3/3 [==============================] - 1s 486ms/step - loss: 0.2041 - accuracy: 0.9661 - val_loss: 0.3164 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "3/3 [==============================] - 1s 477ms/step - loss: 0.1500 - accuracy: 0.9609 - val_loss: 0.2841 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "3/3 [==============================] - 1s 482ms/step - loss: 0.1404 - accuracy: 0.9688 - val_loss: 0.2283 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "3/3 [==============================] - 1s 471ms/step - loss: 0.1022 - accuracy: 0.9766 - val_loss: 0.1319 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "history = model.fit(X, y, batch_size=32, epochs=epochs, validation_split=0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
